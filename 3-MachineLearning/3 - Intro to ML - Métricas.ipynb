{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to ML\n",
    "## Métricas\n",
    "---\n",
    "\n",
    "En la sesión anterior vimos cómo elegir modelos y afinar nuestros modelos de forma que encuentren el mejor compromiso entre el bies y la varizana, es decir evitar que nuestro modelo sobre-entrene (overfit) los datos que usamos durante la fase de entreno y generalice de la mejor forma posible.\n",
    "\n",
    "En la sesión de hoy hablaremos de que métricas nos permiten discriminar los modelos y cómo calcularlas con especial enfasis en métricas de clasificación\n",
    "<div class=\"panel panel-success\">\n",
    "    <div class='panel-heading'>\n",
    "    <h4>Empecemos</h4>\n",
    "    </div>\n",
    "    <div class='panel-body'>\n",
    "    <ol type=\"A\">\n",
    "    <li>Métricas Regresión</li>\n",
    "    <li>Métricas Clasificación</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Metricas para problemas de regression\n",
    "\n",
    "Las métricas más comunes en los problemas de regresión son el **error cuadrático** y el **error absoluto**, y sus distintas modificaciones.\n",
    "\n",
    "### 1.1.2 Errores cuadráticos\n",
    "\n",
    "El **error cuadrático (Squared Error)** de un valor predicho con respecto al valor real, se calcula cómo:\n",
    "\n",
    "$$ SE = \\sum_j\\left[f(X_{j}) - y_j\\right]^2$$\n",
    "\n",
    "\n",
    "**Error cuadrático medio (Mean Squared Error)** Da una idea del error de nuestras predicciones dando más peso a los errores grandes.\n",
    "\n",
    "$$ MSE = \\frac{1}{m}\\sum_j^m \\left[f(X_{j \\cdot}) - y_j\\right]^2 $$\n",
    "\n",
    "**Raiz del error cuadrático medio (Root Mean Square Error)** La raíz cuadrada del MSE produce el error de la raíz cuadrada de la media o la desviación de la raíz cuadrada media (RMSE o RMSD). Tiene las mismas unidades que la cantidad que estima. Para un estimador sin sesgo (bies), el RMSE es la raíz cuadrada de la varianza, es decir la desviación estandar.\n",
    "\n",
    "$$ RMSE = \\sqrt{\\frac{1}{m}\\sum_j^m \\left[f(X_{j \\cdot}) - y_j\\right]^2} $$\n",
    "\n",
    "A pesar de ser una de las métricas más utilizadas, tiene el inconveniente de ser sensible a los valores extremos (outliers). Cuando este comportamiento pueda suponer un problema, los ** errores absolutos** pueden darnos una mejor medida de rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Escribe una función que devuelva el MSE y el RMSE dados dos arrays de numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Utiliza la función del error cuadrático en las métricas de sklearn para crear la funcion de RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Errores absolutos\n",
    "\n",
    "El **error absoluto** (Absolute Error) se define cómo:\n",
    "\n",
    "$$ AE = \\sum_j \\left|f(X_{j \\cdot}) - y_j\\right| $$\n",
    "\n",
    "**Error absoluto medio (Mean Absolute Error)** Es más robusto a los valores extremos y su interpretabilidad es más alta que la del RMSE ya que también está en las unidades de la variable a predecir con la ventaja de que el dato no ha sufrido ninguna transformación.\n",
    "\n",
    "$$ MAE = \\frac{1}{m} \\sum_j^m \\left|f(X_{j \\cdot}) - y_j\\right| $$\n",
    "\n",
    "**Error absoluto medio porcentual (Mean Average Percentage Error)**\n",
    "A pesar de su simpleza, presenta varios inconvenientes a la hora de usarlo de forma práctica. Por ejemplo, no puede usarse cuando el valor de referencia es 0. Además, si se usa para elegir métodos predictivos seleccionará de forma sistemática un metodo que prediga valores bajos.\n",
    "[wiki](https://en.wikipedia.org/wiki/Mean_absolute_percentage_error)\n",
    "\n",
    "$$ MAPE = \\frac{1}{m} \\sum_j^m \\left|\\frac{f(X_{j \\cdot}) - y_j}{y_j}\\right| $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Escribe una función que devuelva el MAE y el MAPE dados dos arrays de numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Compara los resultados con el metodo implementado en sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 A considerar...\n",
    "\n",
    "Notese que las dos métricas expuestas anteriormente pueden considerarse como distancias entre el vector de valores reales y el predicho. De hecho, el RMSE corresponde a la **distancia euclidiana**, también conocida como norma $l_2$ o $\\lVert{v}\\rVert_2$.\n",
    "Por otro lado, el MAE corresponde a la norma $l_1$ o $\\lVert{v}\\rVert_1$. A esta distancia se la conoce como **distancia de manhattan**, porque sólo se puede viajar de un bloque a otro de la ciudad a traves de calles ortogonales.\n",
    "\n",
    "De forma general, una norma $l_k$ o $\\lVert{v}\\rVert_k$ se calcula:\n",
    "\n",
    "$$\\lVert{v}\\rVert_k = \\left(|v_0|^k + ...+ |v_m|^k \\right)^\\frac{1}{k}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Coeficiente de determinación ($R^2$)\n",
    "\n",
    "El coeficiente determina la calidad del modelo para replicar los resultados, y la proporción de variación de los resultados que puede explicarse por el modelo. El valor más alto obtenible será 1, aunque hay casos en los que puede presentar valores negativos. De forma intuitiva, $R^2$ compara el \"fit\" de nuestro modelo al de una linea recta horizontal. Dada una regresión lineal simple, un $R^2$ negativo sólo es posible cuando la ordenada en el origen o la pendiente están restringidas de forma que el mejor modelo es peor que una linea horizontal.\n",
    "\n",
    "Si representamos la **varianza de la variable dependiente** por $\\sigma^{2}$ y la **varianza residual** por $\\sigma _{r}^{2}$, el coeficiente de determinación viene dado por la siguiente ecuación:\n",
    "\n",
    "$$ R^{2}=1- \\frac{\\sigma_{r}^{2}}{\\sigma ^{2}}$$\n",
    "\n",
    "\n",
    "Siendo $\\hat{y}_i$ el valor predicho de la muestra i y $y_i$ el valor real, el $R^2$ estimado sobre $n_{\\text{muestras}}$ se define como:\n",
    "\n",
    "$$ R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=0}^{n_{\\text{samples}} - 1} (y_i - \\hat{y}_i)^2}{\\sum_{i=0}^{n_\\text{samples} - 1} (y_i - \\bar{y})^2}$$\n",
    "donde $$ \\bar{y} =  \\frac{1}{n_{\\text{samples}}} \\sum_{i=0}^{n_{\\text{samples}} - 1} y_i.$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Crea una función que dados dos vectores calcule la función de R²\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Utiliza la función implementada en sklearn y compara los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.5.1 Consideraciones R²\n",
    "\n",
    "1. R² no puede determinar si los coeficientes y las predicciones tienen bies --> Graficar los residuales!\n",
    "\n",
    "1. Cada vez que añadimos un predictor a un modelo, el R² aumenta aunque sea por suerte, pero nunca decrece. Por consiguiente, un modelo con muchos terminos puede parecer mejor simplemente por el hecho de tener más terminos. Para prevenir este efecto, podemos usar el **adjusted R²**, una versión modificada que se ajusta al número de predictores en el modelo. De ésta forma, el R² solo aumenta si el nuevo término mejora el modelo más que por mera suerte. Siempre es más bajo que el R²\n",
    "\n",
    "$$\\bar{R}^2 = 1 - \\frac{N-1}{N-k-1}(1-R^2)$$\n",
    "\n",
    "\n",
    "n – numero de observaciones\n",
    "\n",
    "k – numero de parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### crea una función que devuelva el R² ajustado.\n",
    "### Acuerdate que podemos acceder al número de parametros de un modelo: model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## load linear regression ML model\n",
    "from ... import ...\n",
    "\n",
    "## load the tool to construct polynomial features\n",
    "from sklearn.preprocessing import ...\n",
    "\n",
    "from sklearn.datasets import ...\n",
    "\n",
    "# instancia el dataset y crea variables polinómicas de hasta grado 2\n",
    "data = \n",
    "poly = \n",
    "X_poly =\n",
    "y =\n",
    "\n",
    "## Instancia la regresión lineal\n",
    "LR = LinearRegression()\n",
    "\n",
    "## Para cada grupo de columnas (1, 1-2, 1-2-3, ..., 1-2-...-m) evalua el modelo con la r2 y la r2 ajustada\n",
    "\n",
    "r2 = \n",
    "r2_adj = \n",
    "for ... in range(1, ...):\n",
    "    X =\n",
    "    y_pred = \n",
    "    r2.append()\n",
    "    r2_adj.append()\n",
    "\n",
    "plt.plot(r2, label='r2')\n",
    "plt.plot(r2_adj, label='r2_adj')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Metricas para problemas de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando hablamos de problemas de clasificación, existe una gran variedad de métricas que nos permiten determinar cómo de bueno es nuestro clasificador. La elección de la métrica vendrá determinada por:\n",
    "\n",
    "1. El tipo de predicción: si es una clase o la **probabilidad** de pertenecer a una clase\n",
    "2. Si se trata de un problema balanceado o no\n",
    "\n",
    "### 1.2.1 Matriz de confusión\n",
    "\n",
    "Antes de empezar, consideremos el caso básico de una clasificación binaria en el que intentamos predecir una clase. Imagina que hemos entrenado un modelo y realizado una serie de predicciones. Es fácil entonces crear una tabla que contenga la siguiente información.\n",
    "\n",
    "|                      | Observación: Perro                | Observación: Gato                 |\n",
    "|--------------------- |:---------------------------------:|:---------------------------------:|\n",
    "| **Predicción Perro** |<span style='color:green'>25</span>|<span style='color:red'>3</span>   |\n",
    "| **Predicción Gato**  |<span style='color:red'>9</span>   |<span style='color:green'>19</span>|\n",
    "\n",
    "Esta tabla se conoce cómo matriz de confusión (en ingles, confusion matrix) y es facilmente extendible a problemas de clasificación de varias categorías.\n",
    "\n",
    "Lo que nos dice esta matriz de forma simplificada es:\n",
    "\n",
    "1. En total tenemos 25+3+9+19 = 56 muestras sobre las que hemos realizado predicciones\n",
    "1. De las 56, 25 + 9 = 34 pertenecen a la clase *perro* y 3+19 = 21 pertenecen a la clase *gato*\n",
    "1. De los 34 *perros*, hemos predicho bien la categoría en 25 casos y mal en 9.\n",
    "1. De los 21 *gatos*, hemos predicho bien la categoría gato en 19 casos y mal en 3\n",
    "\n",
    "|                         | Observation Positive     | Observation Negative    |\n",
    "|-------------------------|:------------------------:|:-----------------------:|\n",
    "| **Prediction Positive** |     True Positive        | False Positive (Type I) |\n",
    "| **Prediction Negative** | False Negative (Type II) |     True Negative       |\n",
    "\n",
    "A partir de esta matriz, se construyen la mayoría de métricas asociadas con los problemas de clasificación.\n",
    "\n",
    "### 1.2.2 Métricas según clase predicha\n",
    "**Accuracy**\n",
    "\n",
    "De forma general, ¿cuantas veces predigo la clase correcta? La más común y muchas veces, la más susceptible a darnos un clasificador erroneo, sobre todo en sets de datos no balanceados.\n",
    "\n",
    "$$Accuracy = \\frac{TP+TN}{total} = \\frac{25+19}{56} \\sim 0.786$$\n",
    "\n",
    "**Error Rate**\n",
    "\n",
    "De similar modo, ¿Cuántas veces me equivoco?\n",
    "\n",
    "$$ Error Rate = 1 - Accuracy = \\frac{FP+FN}{total} = \\frac{9+3}{56} \\sim 0.214 $$\n",
    "\n",
    "**Recall (sensitivity)**\n",
    "\n",
    "Cuando es *perro*, ¿cuantas veces predecimos *perro*?\n",
    "\n",
    "$$ Recall = \\frac{TP}{actual Trues} = \\frac{TP}{TP + FN} = \\frac{25}{25 + 9} \\sim 0.735 $$\n",
    "\n",
    "**Specificity**\n",
    "\n",
    "Cuando es *gato*, ¿cuántas veces predecimos *gato*?\n",
    "\n",
    "$$ Specificity = \\frac{TN}{actual Falses} = \\frac{TN}{TN + FP} = \\frac{21}{19 + 9} \\sim 0.75 $$\n",
    "\n",
    "** Precision **\n",
    "\n",
    "Cuando predecimos *perro*, cuantas veces es correcto?\n",
    "\n",
    "$$ Precision = \\frac{TP}{predicted Trues} = \\frac{TP}{TP + FP} = \\frac{25}{25 + 3} \\sim 0.892 $$\n",
    "\n",
    "**F1-score**\n",
    "\n",
    "A menudo es conveniente **combinar la precision y el recall en una sola métrica** para comparar de forma sencilla dos clasificadores. En vez de calcular una media de la precisión y el recall, se calcula su **media harmónica**. De esta forma se da más peso a los valores bajos por lo que sólo se conseguirá un F1-score alto si ambas, Precision y Recall, son altas.\n",
    "\n",
    "$$F_1= \\frac{1}{\\frac{1}{precision} + \\frac{1}{recall}} = 2 \\times \\frac{precision \\times recall}{precision + recall} = \\frac{TP}{TP + \\frac{FN + FP}{2}} $$\n",
    "\n",
    "\n",
    "Vamos a ver un ejemplo de estas métricas. Para ello, usaremos los datos de vinos que vienen por defecto en la libreria de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Cargamos los datos de vinos y lo necesario para hacer analisis de datos\n",
    "\n",
    "\n",
    "data = \n",
    "df = pd.DataFrame(data.data)\n",
    "df.columns = data.feature_names\n",
    "df['y'] = data.target\n",
    "\n",
    "# Vamos a forzar solo que distinga entre la clase 0 y las demas\n",
    "# Asigna a la variable 'y' la clase 0 cuando sea 0 y 1 en caso contrario\n",
    "df['y'] = \n",
    "\n",
    "# importa el modulo de regresión logística\n",
    "\n",
    "# importa el modulo de StratifiedKfold\n",
    "\n",
    "# importa el modulo de cross_val_predict\n",
    "\n",
    "#importa el modulo necesario para realizar la partición entre train y test\n",
    "\n",
    "# divide el dataset en train y test con un tamaño de test del 20% de los datos\n",
    "\n",
    "# usa el StratifiedKFold para dividir el X_train en 5 partes. Usa el random_state = 1234\n",
    "\n",
    "# instancia una regresión logistica\n",
    "\n",
    "# usa la función de cross_val_predict para entrenar y evaluar la regresión logística usando el StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos realizado las predicciones, veamos cómo se comporta calculando las métricas comentadas anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ..., ..., ..., ...\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(...))\n",
    "print(\"Precision:\", precision_score(...))\n",
    "print(\"Recall:\", recall_score(...))\n",
    "print(\"F1:\", f1_score(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra funcionalidad que nos da una visión panorámica de nuestro clasificador es..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ...\n",
    "print(classification_report(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Metricas para predicciones probabilisticas\n",
    "\n",
    "Muchas veces no solo nos conformaremos con predecir una clase, si no que tendremos que predecir la *probabilidad* de pertenecer a una clase.\n",
    "\n",
    "Varios métodos de clasificación de ML son aptos para este tipo de tarea. En sklear, además del método `clf.predict()` de algunos estimadores, tendremos el método `clf.predict_proba()`, que nos devolverá la probabilidad de pertenecer a cada una de las clases.\n",
    "\n",
    "En realidad, un clasificador calcula la probabilidad y, en base a un umbral, decide la clase a la que pertenece.\n",
    "Por defecto, los algoritmos de ML de sklearn tienen un umbral de 0.5. Es decir, si la probabilidad de pertenecer a una clase es mayor que 0.5, le asigna la etiqueta de esa clase.\n",
    "\n",
    "**¿Qué implica esto?**\n",
    "\n",
    "Básicamente, implica que si jugamos con el umbral de decisión para un predictor probabilístico, podemos alterar las métricas de performance a nuestra voluntad...\n",
    "\n",
    "### Precision vs recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "x = np.r_[0:1:1000j]\n",
    "y = np.random.binomial(1, x)\n",
    "\n",
    "def plot_threshold(threshold=0.5):\n",
    "    true_pos = (x > threshold) * (y > 0)\n",
    "    plt.plot(x[true_pos], y[true_pos], '.', label=\"True Positive\")\n",
    "    false_pos = (x > threshold) * (y == 0)\n",
    "    plt.plot(x[false_pos], y[false_pos], '.', label=\"False Positive\")\n",
    "    true_neg = (x <= threshold) * (y == 0)\n",
    "    plt.plot(x[true_neg], y[true_neg], '.', label=\"True Negative\")\n",
    "    false_neg = (x <= threshold) * (y > 0)\n",
    "    plt.plot(x[false_neg], y[false_neg], '.', label=\"False Negative\")\n",
    "    plt.axvline(threshold, c='k')\n",
    "    plt.ylim(-0.5, 1.5)\n",
    "    plt.legend()\n",
    "    \n",
    "    try:\n",
    "        precision = 1.0 * sum(true_pos) / (sum(true_pos) + sum(false_pos))\n",
    "    except ZeroDivisionError:\n",
    "        precision = 1\n",
    "    recall = 1.0 * sum(true_pos) / (sum(true_pos) + sum(false_neg))\n",
    "    plt.title('Precision: %0.2f, Recall: %0.2f' % (precision, recall))\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_threshold, threshold=(0, 1, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No tiene sentido hablar de éstas métricas de forma independiente, ya que podemos alterar virtualmente su valor al modificar el umbral de decisión. Por ejemplo, si seteamos el umbral de decision muy alto de forma que el clasificador nos devuelva siempre la clase 0, nuestro clasificador tendrá una precision del 100% y un recall nulo.\n",
    "\n",
    "En el caso contrario, si el umbral lo ponemos de forma que facilmente prediga la clase positiva, nuestro clasificador tendrá un recall del 100% a expensas de la precisión.\n",
    "\n",
    "Este comportamiento no tiene por que ser negativo per se. Dependerá del tipo de problema que estemos tratando. \n",
    "\n",
    "Por ejemplo, en un caso de detección de cancer...que es mejor? Una precision alta o un recall alto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vamos a predecir las probabilidades del ejercicio anterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importa el metodo que nos permite encontrar la curva de precisión y recall\n",
    "from sklearn.metrics import ...\n",
    "\n",
    "# calcula la precision, el recall y los umbrales\n",
    "prec, rec, thre = ...\n",
    "\n",
    "# haz un plot de la precision y el recall en función de los umbrales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotea la precisión en funcion del recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "\n",
    "De forma similar a la curva de precision-recall, la curva ROC (*Receiver Operating Characteristic*) es otra herramienta típica usada en clasificadores binarios.\n",
    "\n",
    "A diferencia de la curva PR, la curva ROC compara el True Positive Rate (Recall) y el False Positive Rate (1 - specifity). Recuerda que la *specifity* es el True Negative Rate, el ratio de veces que la clase negativa se clasifica correctamente.\n",
    "\n",
    "Otra forma de comparar clasificadores es comparando el area bajo la curva ROC (Area Under the Curve, AUC). Éste parametro tiene cómo límite superior 1, mientras que un valor de 0.5 corresponde a un clasificador completamente aleatorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Repite el ejercicio anterior pero con la curva ROC\n",
    "from sklearn.metrics import ...\n",
    "\n",
    "fpr, tpr, thre = ...\n",
    "roc_auc = ...\n",
    "\n",
    "# plotea los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que la curva ROC y la Prec vs Recall son muy parecidas, uno puede tener dudas al tener que elegir una de ellas. Cómo guía no exhaustiva, uno puede decantarse en función del problema que tenga. Concretamente, en casos no balanceados o cuando una clase nos importa más que la otra, la curva PR nos aportará más información que la curva ROC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Carga el set de datos 'data/creditcard.csv'\n",
    "df_fraud = \n",
    "\n",
    "## Separa el set de datos en train y test\n",
    "\n",
    "## crea un stratified kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## usa una regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### predice las clases\n",
    "y_pred_imb = \n",
    "\n",
    "### predice la probabilidad de las clases\n",
    "y_proba_imb = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score())\n",
    "print(\"Precision:\", precision_score())\n",
    "print(\"Recall:\", recall_score())\n",
    "print(\"F1:\", f1_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thre_roc = \n",
    "auc_roc = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## busca la funcionalidad que permite calcular un area bajo la curva\n",
    "from sklearn.metrics import ...\n",
    "\n",
    "# calcula la precision, el recall y los umbrales\n",
    "prec, rec, thre = \n",
    "#calcula el AUC de la curva PR\n",
    "auc_pr = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## haz un plot de la precisión -vs- el recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
